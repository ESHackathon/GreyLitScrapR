% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/greyLitScrapR.R
\name{get_all_articles_from_site}
\alias{get_all_articles_from_site}
\title{Get all articles from a given site}
\usage{
get_all_articles_from_site(
  base_url,
  first_page = 1,
  last_page = 1,
  xpath_title = NULL,
  xpath_link = NULL,
  xpath_date = NULL,
  session = NULL
)
}
\arguments{
\item{base_url}{the URL containing up to the page number}

\item{first_page}{the first page}

\item{last_page}{the last page}

\item{xpath_title}{the xpath to obtain titles}

\item{xpath_link}{the xpath to obtain links}

\item{xpath_date}{the xpath to obtain dates}

\item{session}{optional session (from \code{\link[polite:bow]{polite::bow()}}) to reuse}
}
\value{
a dataframe containing the page URL
The titles, and the links
\preformatted{
data,.frame(page_url, titles, links)
}
}
\description{
Gets the titles, links, and dates of individual articles
from a given site
}
\seealso{
\code{\link[=get_page_number]{get_page_number()}} to extract first and last page numbers
}
